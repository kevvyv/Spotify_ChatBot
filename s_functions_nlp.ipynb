{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary that stores all the emotions with their respective genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_genre_map_1 = {\n",
    "    \"energetic\": [\"afrobeat\", \"breakbeat\", \"drum-and-bass\", \"dubstep\", \"hardcore\", \"hardstyle\", \"punk\", \"ska\", \"metal-misc\", \"hip-hop\", \"reggaeton\", \"house\", \"samba\", \"sertanejo\"],\n",
    "    \"calm\": [\"acoustic\", \"ambient\", \"bossanova\", \"new-age\", \"piano\", \"sleep\", \"rainy-day\"],\n",
    "    \"nostalgic\": [\"anime\", \"disco\", \"j-pop\", \"j-rock\", \"rock-n-roll\", \"rockabilly\", \"grunge\", \"emo\", \"indie-pop\", \"j-idol\"],\n",
    "    \"soulful\": [\"blues\", \"soul\", \"funk\"],\n",
    "    \"happy\": [\"party\", \"pop\", \"pop-film\"],\n",
    "    \"intense\": [\"black-metal\", \"death-metal\", \"grindcore\", \"heavy-metal\", \"metalcore\"],\n",
    "    \"romantic\": [\"romance\", \"love-songs\"],\n",
    "    \"introspective\": [\"alternative\", \"folk\", \"singer-songwriter\", \"songwriter\", \"british\"],\n",
    "    \"upbeat\": [\"bluegrass\", \"brazil\", \"dancehall\", \"funk\", \"reggae\"],\n",
    "    \"reflective\": [\"british\", \"indie-pop\", \"post-dubstep\", \"sad\", \"piano\"],\n",
    "    \"brooding\": [\"alt-rock\", \"goth\", \"industrial\", \"psych-rock\"],\n",
    "    \"groovy\": [\"groove\", \"club\", \"dance\", \"electro\"],\n",
    "    \"adventurous\": [\"dub\", \"electronic\", \"idm\", \"psycho-rock\", \"rockabilly\", \"trance\"],\n",
    "    \"traditional\": [\"country\", \"folklore\"],\n",
    "    \"cultural\": [\"french\", \"german\", \"iranian\", \"malay\", \"philippines-opm\"],\n",
    "    \"energizing\": [\"techno\", \"trance\", \"dubstep\", \"electronic\"],\n",
    "    \"relaxing\": [\"chill\", \"easy-listening\", \"lounge\", \"soft-rock\", \"ambient\"],\n",
    "    \"uplifting\": [\"happy\", \"power-pop\", \"k-pop\"],\n",
    "    \"emotional\": [\"r-n-b\", \"soul\"],\n",
    "    \"mysterious\": [\"instrumental\", \"jazz\"],\n",
    "    \"fiery\": [\"flamenco\", \"spanish\"],\n",
    "    \"reflective\": [\"acoustic\", \"chill\", \"classical\", \"indie-folk\", \"jazz\", \"rainy-day\", \"sleep\"],\n",
    "    \"motivational\": [\"motivation\", \"work-out\"],\n",
    "    \"sad\": [\"emo\", \"indie\", \"sad\", \"indie-pop\", \"singer-songwriter\", \"acoustic\", \"piano\", \"rainy-day\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for embedding input and matching the embeddings with the proper emotion and genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd_input(input):\n",
    "    model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True,\n",
    "                                  )\n",
    "    model.eval()\n",
    "    tkn = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    episode_summaries = [input]\n",
    "    eps_tokenized = []\n",
    "\n",
    "    for ep in episode_summaries:\n",
    "        marked_text = \"[CLS] \" + str(ep) + \" [SEP]\"\n",
    "        tokenized = tkn.tokenize(marked_text)\n",
    "        eps_tokenized.append(tokenized)\n",
    "\n",
    "    eps_tokenized\n",
    "\n",
    "    eps_embeddings = []\n",
    "\n",
    "\n",
    "    start = 1\n",
    "    max_length = 512  \n",
    "    count = 0\n",
    "\n",
    "    for token_s in eps_tokenized:\n",
    "    # Turns our tokens into their index in the corpus\n",
    "        indexed_tokens = tkn.convert_tokens_to_ids(token_s)\n",
    "    \n",
    "    # Truncate the sequence if it's longer than the max length\n",
    "        indexed_tokens = indexed_tokens[:max_length]\n",
    "        segments_ids = [start] * len(indexed_tokens)\n",
    "    \n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # Generates the embedding\n",
    "        with torch.no_grad():\n",
    "            outputs = model(tokens_tensor, segments_tensors)\n",
    "            hidden_states = outputs[2]\n",
    "\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    \n",
    "    # Adding the embedding to our list, more specifically, the embedding of the first and last token\n",
    "        token_vecs = hidden_states[-2][0]\n",
    "        eps_embeddings.append(token_vecs)\n",
    "        count +=1\n",
    "        if count % 1000 == 0:\n",
    "            print(count)\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    embedded_eps = []\n",
    "    for vec in eps_embeddings:\n",
    "        sentence_embedding = torch.mean(vec, dim= 0)\n",
    "        embedded_eps.append(sentence_embedding)\n",
    "\n",
    "\n",
    "#token_vecs = hidden_states[-2][0]\n",
    "#sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "\n",
    "    return embedded_eps\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_comparision(inpt):\n",
    "\n",
    "  \n",
    "  emotions = ['energetic','calm','nostalgic', 'soulful', 'happy', 'intense', 'romantic', 'introspective', 'upbeat', 'reflective', 'brooding', 'playful', 'groovy', 'emotional', 'adventurous', 'traditional',\n",
    " 'cultural','energizing','relaxing','uplifting', 'sensual', 'mysterious', 'fiery', 'exotic', 'motivational', 'sad']\n",
    "  loaded_embeddings_np = np.load('emotion_embeddings.npy', allow_pickle=True)\n",
    "  sentence_np = embedd_input(inpt)[0].numpy()\n",
    "  loaded_embeddings_np = np.load('emotion_embeddings.npy', allow_pickle=True)\n",
    "  similarity_scores = cosine_similarity([sentence_np], loaded_embeddings_np)[0]\n",
    "  top_3_indices = np.argsort(similarity_scores)[-3:][::-1]\n",
    "  top_3_emotions = [(emotions[index], similarity_scores[index]) for index in top_3_indices]\n",
    "  rtn = []\n",
    "  for x in top_3_emotions:\n",
    "    rtn.append(emotion_genre_map_1[x[0]])\n",
    "\n",
    "\n",
    "  return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['party', 'pop', 'pop-film'],\n",
       " ['blues', 'soul', 'funk'],\n",
       " ['motivation', 'work-out']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_comparision(\"I am so excited, I won so much money!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
